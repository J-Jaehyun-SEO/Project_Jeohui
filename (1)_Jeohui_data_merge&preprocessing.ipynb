# 필요한 패키지 설치
!pip install --upgrade matplotlib kiwipiepy pandas tqdm konlpy xlsxwriter
!pip install numpy==1.23.5

# Nanum 폰트 설치
!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm -rf ~/.cache/matplotlib

# 라이브러리 임포트
import pandas as pd
import numpy as np
import re
from tqdm import tqdm
from kiwipiepy import Kiwi
import matplotlib.pyplot as plt
import matplotlib as mpl

# NLTK 다운로드
nltk.download('punkt')

##(1)DATA LOADING

###데이터 1 - 조선, 동아 1954-1999

old_news_df = pd.read_csv('/content/저희_조선동아_1954_1999_문장분리.csv')
old_news_df=old_news_df.drop(columns=['index','sents','저희_sents','저희_str','저희_문장_index'])
old_news_df

import pandas as pd
import re
from kiwipiepy import Kiwi

# Kiwi 형태소 분석기
kiwi = Kiwi()

# '저희'가 있는 문장 추출 및 저장할 리스트
sentences_with_jeohee = []

# 문장 구분 기호
split_chars = r'[!?。.．。!？]'
split_chars_2 = r'[.!?]'

# 원본 데이터프레임에 인덱스 추가
old_news_df.reset_index(inplace=True)

# 'text' 열에서 '저'와 '희' 사이의 스페이스 제거
old_news_df['text'] = old_news_df['text'].str.replace(r'저\s+희', '저희', regex=True)

for _, row in old_news_df.iterrows():
    # 문장 부호 통일
    text = row['text'].replace('。', '.')
    text = text.replace('．', '.')
    text = text.replace('!', '!')
    text = text.replace('？', '?')

    # '저희'가 있는 문장 추출
    sentences = re.split(split_chars_2, text)  # 통일된 문장 부호 기준으로 분리
    for sentence in sentences:
        if '저희' in sentence:
            if sentence.count('저희') >= 3:
                # '저희'가 3개 이상이면 kiwi로 문장 분리
                kiwi_sentences = kiwi.split_into_sents(sentence)
                for kiwi_sentence in kiwi_sentences:
                    if '저희' in kiwi_sentence.text:
                        sentences_with_jeohee.append((kiwi_sentence.text.strip(), row['index']))
            else:
                sentences_with_jeohee.append((sentence.strip(), row['index']))

# 새로운 데이터프레임 생성
new_df_jeohee = pd.DataFrame(sentences_with_jeohee, columns=['jeohee_sentence', 'original_index'])

# '저희' 개수 세는 컬럼 추가
new_df_jeohee['jeohee_count'] = new_df_jeohee['jeohee_sentence'].apply(lambda x: x.count('저희'))

# 앞, 뒤 문장 컬럼 추가
new_df_jeohee['previous_sentence'] = ''
new_df_jeohee['next_sentence'] = ''

# 앞, 뒤 문장 붙이기
for index, row in new_df_jeohee.iterrows():
    # 원본 데이터프레임에서 해당 문장 찾기
    original_text = old_news_df.loc[row['original_index'], 'text']
    jeohee_index = row['original_index']

    if jeohee_index is not None:
        original_sentences = re.split(split_chars_2, original_text)

        # 부분 문자열 포함 여부로 찾기
        jeohee_sentence_index = None
        for i, s in enumerate(original_sentences):
            if row['jeohee_sentence'] in s:
                jeohee_sentence_index = i
                break

        if jeohee_sentence_index is not None:
            # 앞 문장 추가
            if jeohee_sentence_index > 0:
                new_df_jeohee.loc[index, 'previous_sentence'] = original_sentences[jeohee_sentence_index - 1].strip()

            # 뒤 문장 추가
            if jeohee_sentence_index < len(original_sentences) - 1:
                new_df_jeohee.loc[index, 'next_sentence'] = original_sentences[jeohee_sentence_index + 1].strip()

# 문장 구분 없는 경우 처리
for index, row in new_df_jeohee.iterrows():
    if row['previous_sentence'] == '' and row['next_sentence'] == '':
        # 문장 구분이 없는 경우 kiwi로 분리
        kiwi_sentences = kiwi.split_into_sents(row['jeohee_sentence'])
        if len(kiwi_sentences) > 1:
            new_df_jeohee.loc[index, 'previous_sentence'] = kiwi_sentences[0].text.strip()
            new_df_jeohee.loc[index, 'next_sentence'] = '. '.join([s.text for s in kiwi_sentences[1:]]).strip()

# 원본 데이터프레임의 관련 열을 새로운 데이터프레임에 병합
new_df_jeohee = new_df_jeohee.merge(old_news_df, left_on='original_index', right_on='index', suffixes=('', '_original'))

# 불필요한 인덱스 열 삭제
new_df_jeohee.drop(columns=['index', 'original_index'], inplace=True)

# 'jeohee_count'가 2 이상인 문장 다시 처리
for index, row in new_df_jeohee[ (new_df_jeohee['jeohee_count'] >= 2) | (new_df_jeohee['jeohee_sentence'].str.len() >= 200) ].iterrows():
    sentence = row['jeohee_sentence']
    kiwi_sentences = kiwi.split_into_sents(sentence)
    new_sentences = [s.text for s in kiwi_sentences]

    # 문장 재구성
    previous_sentence = ''
    jeohee_sentence = ''
    next_sentence = ''

    for i, s in enumerate(new_sentences):
        if '저희' in s:
            jeohee_sentence = s.strip()
            if i > 0:
                previous_sentence = new_sentences[i-1].strip()
            if i < len(new_sentences) - 1:
                next_sentence = new_sentences[i+1].strip()
            break

    new_df_jeohee.at[index, 'previous_sentence'] = previous_sentence
    new_df_jeohee.at[index, 'jeohee_sentence'] = jeohee_sentence
    new_df_jeohee.at[index, 'next_sentence'] = next_sentence

# 'jeohee_count' 업데이트
new_df_jeohee['jeohee_count'] = new_df_jeohee['jeohee_sentence'].apply(lambda x: x.count('저희'))

# 결과 확인
new_df_jeohee.head()


jeohee_count_stats = new_df_jeohee['jeohee_count'].value_counts()
new_df_jeohee = new_df_jeohee[new_df_jeohee['jeohee_count'] == 1]
new_df_jeohee = new_df_jeohee.sort_values('jeohee_count',ascending=False)

# 문장 부호 치환 함수
def replace_punctuation(text):
    text = text.replace('。', '.')
    text = text.replace('．', '.')
    text = text.replace('!', '!')
    text = text.replace('？', '?')
    text = text.replace('?', '?')
    
    return text

# 문장 처리 후 적용할 위치
# 원본 데이터프레임의 관련 열을 병합한 후 문장 부호를 치환합니다.
new_df_jeohee = new_df_jeohee.merge(old_news_df, left_on='original_index', right_on='index', suffixes=('', '_original'))

# replace_punctuation 함수를 'context' 컬럼에 적용
new_df_jeohee['context'] = new_df_jeohee['jeohee_sentence'].apply(replace_punctuation)

# 불필요한 인덱스 열 삭제
new_df_jeohee.drop(columns=['index', 'original_index'], inplace=True)


저희 개별 문장 추출

# Function to extract sentences containing a specific keyword
def extract_sentences(text, word):
    sentences = text.split('.')
    return '. '.join(sentence.strip() + '.' for sentence in sentences if word.lower() in sentence.lower())

# Assuming df is defined earlier and has a column named 'text'

# Apply the function to extract sentences containing '저희'
new_df['extracted_sentences'] = new_df['context'].apply(lambda x: extract_sentences(x, '저희'))
new_df

2 개 나란히 배령된 중복 문장 확인

new_df['duplicates'] = new_df['extracted_sentences'].duplicated(keep=False)


연속해서 저희가 와서 두 문장이 중복되면, 문장을 분할해서 한 문장만 남기기.

for i in range(1, len(new_df)):
    if new_df.loc[i, 'duplicates'] and new_df.loc[i-1, 'extracted_sentences'] == new_df.loc[i, 'extracted_sentences']:
        split_sentences = new_df.loc[i, 'extracted_sentences'].split('.')
        if split_sentences:
            new_df.loc[i-1, 'extracted_sentences'] = split_sentences[0] + '.'
            if len(split_sentences) > 1:
                new_df.loc[i, 'extracted_sentences'] = '.'.join(split_sentences[1:]) + '.'

# 중복된 값 찾기
duplicates = new_df['extracted_sentences'].duplicated(keep=False)

# 중복된 값의 개수 세기
num_duplicates = duplicates.sum()

print(num_duplicates)

new_df_unique = new_df.drop_duplicates(subset=['extracted_sentences'], keep='first')
new_df_unique = new_df_unique[new_df_unique['extracted_sentences'] != '.']
new_df_unique
new_df=new_df_unique

###데이터 2- 조선, 동아 1990-2024(0525)



recent_news_df = pd.read_excel('/content/bigkinds/bigkinds_JOSEON_DONGA.xlsx')

#recent_news_df = recent_news_df.drop(columns=['URL'])
recent_news_df['year'] = recent_news_df['Published Date'].str[:4]
recent_news_df['text'] = recent_news_df['Title'] + ' ' + recent_news_df['Body']
recent_news_df=recent_news_df.drop(columns=['URL', 'Category','Published Date','Title','Body'])
recent_news_df.rename(columns={'Newspaper': 'publisher'}, inplace=True)
recent_news_df['publisher'] = recent_news_df['publisher'].replace({'동아일보': 'donga', '조선일보': 'chosun'})
recent_news_df['text'] = recent_news_df['text'].astype(str)

import re

special_chars = []
for index, row in recent_news_df.iterrows():
    text = row['text']
    # 특수 문자 추출
chars = re.findall(r'[^a-zA-Z0-9ㄱ-ㅎㅏ-ㅣ가-힣\s\u2E80-\u2EFF\u31C0-\u31EF\u3200-\u32FF\u3400-\u4DBF\u4E00-\u9FFF\uF900-\uFAFF]', text)
special_chars.extend(chars)

# 중복 제거
unique_special_chars = list(set(special_chars))

print(unique_special_chars)

new_df_jeohee_2 = new_df_jeohee
new_df_jeohee_2

####중복 값 검증 및 처리

# 중복된 값 찾기
duplicates = new_df_jeohee_2['jeohee_sentence'].duplicated(keep=False)

# 중복된 값의 개수 세기
num_duplicates = duplicates.sum()

print(num_duplicates)

중복되는 행들간에 값이 완전히 겹치면 하나만 남기고 제거하고, 총 몇개를 제거했는지 프린트



# 모든 열의 값이 완전히 겹치는 경우 제거
before_count = len(new_df_jeohee_2)
new_df_jeohee_2.drop_duplicates(subset=new_df_jeohee_2.columns, inplace=True)
after_count = len(new_df_jeohee_2)

# 제거된 행 개수 출력
print("제거된 행 개수:", before_count - after_count)

중에서 jeohee_sentence jeohee_count previous_sentence next_sentence 까지 겹치고 나머지가 다른 경우에는 중복 값을 제거

# 'jeohee_sentence', 'jeohee_count', 'previous_sentence', 'next_sentence' 컬럼 기준으로 중복 제거
before_count = len(new_df_jeohee_2)
new_df_jeohee_2.drop_duplicates(subset=['jeohee_sentence', 'jeohee_count', 'previous_sentence', 'next_sentence'], inplace=True)
after_count = len(new_df_jeohee_2)

# 제거된 행 개수 출력
print("제거된 행 개수:", before_count - after_count)

import pandas as pd

# 'jeohee_sentence' 컬럼을 기준으로 그룹화하고, 각 그룹 내에서 다른 컬럼의 차이 확인
diff_dfs = []
for sentence, group in duplicate_sentences.groupby('jeohee_sentence'):
    if len(group) > 1:
        diff_df = group[['jeohee_sentence', 'jeohee_count', 'previous_sentence', 'next_sentence']].drop_duplicates()
        diff_df['duplicate_group'] = sentence
        diff_dfs.append(diff_df)

# 차이점을 보여주는 DataFrame 생성
result_df = pd.concat(diff_dfs)
result_df

전체 df 에서 위와 같이 중복을 검증해보고, 차이나는 글자수가 50자 이내인 경우, 중복되는 값중 더 글자 수가 작은 값을 제거하고 한 개만 남김

import pandas as pd

def remove_duplicates_by_char_count(df):
    before_count = len(df)

    # 'jeohee_sentence' 컬럼을 기준으로 그룹화
    for sentence, group in df.groupby('jeohee_sentence'):
        if len(group) > 1:
            # 각 그룹 내에서 문자열 길이를 기준으로 정렬
            group_sorted = group.copy()
            group_sorted['sentence_length'] = group_sorted['jeohee_sentence'].apply(len)
            group_sorted = group_sorted.sort_values(by='sentence_length', ascending=True)

            # 가장 짧은 문자열과 나머지 문자열들의 길이 차이 계산
            shortest_length = group_sorted.iloc[0]['sentence_length']
            length_diffs = group_sorted['sentence_length'] - shortest_length

            # 길이 차이가 50 이하인 행 제거
            rows_to_remove = group_sorted[length_diffs <= 50].index[1:]  # 첫 번째 행 (가장 짧은 문자열)은 제외
            df.drop(index=rows_to_remove, inplace=True)

    after_count = len(df)
    print("제거된 행 개수:", before_count - after_count)
    return df


# 함수 호출
new_df_jeohee_2 = remove_duplicates_by_char_count(new_df_jeohee_2)
new_df_jeohee_2


중복행 검증

# 중복된 값 찾기
duplicates = new_df_jeohee_2['jeohee_sentence'].duplicated(keep=False)

# 중복된 값만 필터링
duplicate_sentences = new_df_jeohee_2[duplicates]

# 중복된 값이 포함된 DataFrame 출력
duplicate_sentences

###두 데이터 통합해 처리

new_df_jeohee_1 = recent_news_df
new_df_jeohee_2 = old_news_df

new_df_jeohee_1

new_df_jeohee_2

# 두 데이터프레임 합치기

# 'year' 컬럼을 문자열로 변환
new_df_jeohee_1['year'] = new_df_jeohee_1['year'].astype(str)
new_df_jeohee_2['year'] = new_df_jeohee_2['year'].astype(str)

# 두 데이터프레임을 concat으로 병합
merged_df = pd.concat([new_df_jeohee_1, new_df_jeohee_2]).reset_index(drop=True)

merged_df

#저회 -> 저희
import re

# 찾을 패턴 정의
pattern = r"저\s*회"

# 각 컬럼별로 값 변경
for column in ['previous_sentence', 'jeohee_sentence', 'next_sentence']:
    new_df_jeohee[column] = new_df_jeohee[column].str.replace(pattern, "저희", regex=True)

##전체 토크나이징 코드

import pandas as pd
import re
from konlpy.tag import Kkma
from kiwipiepy import Kiwi

# Kiwi 형태소 분석기
kiwi = Kiwi()

# 특수기호만 있는 문장 패턴
pattern = r"^[^\w\s]+$"

# 원본 데이터프레임에 인덱스 추가
old_news_df.reset_index(inplace=True)

# 'text' 열에서 '저'와 '희' 사이의 스페이스 제거
old_news_df['text'] = old_news_df['text'].str.replace(r'저\s+희', '저희', regex=True)
old_news_df = old_news_df.replace('\n', '-', regex=True)

# 특수 기호들을 처리하는 함수
def process_special_characters(text):
    # 여는 큰 따옴표로 처리할 특수 기호들
    opening_quotation_marks = {'『', '「','‘','“'}
    for mark in opening_quotation_marks:
        text = text.replace(mark, '"')

    # 닫는 큰 따옴표로 처리할 특수 기호들
    closing_quotation_marks = {'』', '」','”',' ’'}
    for mark in closing_quotation_marks:
        text = text.replace(mark, '"')
    #'…'는 미처리
    # '*'으로 처리할 특수 기호들
    star_marks = {'○','●', '▼', '◇', '△',  '▲'}
    for mark in star_marks:
        text = text.replace(mark, '*')

    # 제거할 특수 기호들
    remove_marks = {'|', '｜','-', '—'}
    for mark in remove_marks:
        text = text.replace(mark, '')

    return text

# 데이터프레임의 각 텍스트를 일괄 토크나이징
tokenized_texts = []
for _, row in old_news_df.iterrows():
    text = row['text']

    # 특수 기호 처리
    text = process_special_characters(text)

    # 기존 특수 기호 처리
    text = text.replace('。', '.').replace('．', '.').replace('!', '!').replace('？', '?')

    # 토크나이징 수행
    tokenized_sentences = kiwi.split_into_sents(text)
    tokenized_texts.append((tokenized_sentences, row['index']))



# '저희'가 포함된 문장과 그 앞뒤 문장을 저장할 리스트
sentences_with_jeohee = []

# '저희'가 포함된 문장과 그 앞뒤 문장을 추출
for tokenized_sentences, idx in tokenized_texts:
    sentences = [sentence.text for sentence in tokenized_sentences]
    for i, sentence in enumerate(sentences):
        if '저희' in sentence:
            # 특수기호만 있는 문장은 제외
            previous_sentence = sentences[i-1] if i > 0 and not re.match(pattern, sentences[i-1].strip()) else ''
            next_sentence = sentences[i+1] if i < len(sentences) - 1 and not re.match(pattern, sentences[i+1].strip()) else ''
            sentences_with_jeohee.append((previous_sentence.strip(), sentence.strip(), next_sentence.strip(), idx))

# 새로운 데이터프레임 생성
new_df_jeohee = pd.DataFrame(sentences_with_jeohee, columns=['previous_sentence', 'jeohee_sentence', 'next_sentence', 'original_index'])

# '저희' 개수 세는 컬럼 추가
new_df_jeohee['jeohee_count'] = new_df_jeohee['jeohee_sentence'].apply(lambda x: x.count('저희'))

# 원본 데이터프레임 병합
new_df_jeohee = new_df_jeohee.merge(old_news_df, left_on='original_index', right_on='index', suffixes=('', '_original'))

# 불필요한 인덱스 열 삭제
new_df_jeohee.drop(columns=['index', 'original_index'], inplace=True)

# '저희' 개수 업데이트
new_df_jeohee['jeohee_count'] = new_df_jeohee['jeohee_sentence'].apply(lambda x: x.count('저희'))


####중복 값 검증 및 처리

import pandas as pd

def remove_duplicates_by_char_count(df):
    before_count = len(df)

    # 'jeohee_sentence' 컬럼을 기준으로 그룹화
    for sentence, group in df.groupby('jeohee_sentence'):
        if len(group) > 1:
            # 각 그룹 내에서 문자열 길이를 기준으로 정렬
            group_sorted = group.copy()
            group_sorted['sentence_length'] = group_sorted['jeohee_sentence'].apply(len)
            group_sorted = group_sorted.sort_values(by='sentence_length', ascending=True)

            # 가장 짧은 문자열과 나머지 문자열들의 길이 차이 계산
            shortest_length = group_sorted.iloc[0]['sentence_length']
            length_diffs = group_sorted['sentence_length'] - shortest_length

            # 길이 차이가 50 이하인 행 제거
            rows_to_remove = group_sorted[length_diffs <= 50].index[1:]  # 첫 번째 행 (가장 짧은 문자열)은 제외
            df.drop(index=rows_to_remove, inplace=True)

    after_count = len(df)
    print("제거된 행 개수:", before_count - after_count)
    return df


# 함수 호출
new_df_jeohee = remove_duplicates_by_char_count(new_df_jeohee)
new_df_jeohee
